{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRQBFxfZGGi27vNBkSqi8+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leilafarsani/Text-Mining---NLP/blob/starter/TextMining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##NLTK\n",
        "\n",
        "Natural Language Toolkit (NLTK)\n",
        "\n",
        "[https://www.nltk.org/](https://www.nltk.org/)\n",
        "\n",
        "*   NLTK is a platform for building Python programs to work with human language data.\n",
        "\n"
      ],
      "metadata": {
        "id": "-q5r2PY8WR_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "U-8G_TbHWhtr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (nltk.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWaZUpRWWtYE",
        "outputId": "57e7f42a-d98c-4fd8-cfa2-ac2268a327b4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG3GFiNbamIK",
        "outputId": "793da728-d2f5-4f5d-c023-0df81cfe24e5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text\n",
        "text1 = 'Hi, I am Leila. I am starting to learn Text Mining.'"
      ],
      "metadata": {
        "id": "0LOrRysuWuoq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLnVbd8FZ2BK",
        "outputId": "7028cf3a-9c66-49e4-cb59-82bd5621046b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi, I am Leila.', 'I am starting to learn Text Mining.']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text\n",
        "text2 = \"Natural language processing is fascinating. It helps computers understand human language.\""
      ],
      "metadata": {
        "id": "EI_RDSxjd2pP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize into sentences\n",
        "sentences = sent_tokenize(text1)\n",
        "print(\"Sentences:\", sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gab7H4QHeIr_",
        "outputId": "4bb1529b-d0c7-4fff-f728-08411414c0bc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences: ['Hi, I am Leila.', 'I am starting to learn Text Mining.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize into words\n",
        "words = word_tokenize(text2)\n",
        "print(\"Words:\", words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMqlyLYreeu0",
        "outputId": "89f09bb9-dedc-4c5c-f0ee-524e1f7ff2de"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words: ['Natural', 'language', 'processing', 'is', 'fascinating', '.', 'It', 'helps', 'computers', 'understand', 'human', 'language', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "print(\"After removing stop words:\", filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcGG-9LOekMB",
        "outputId": "30116cd4-3482-4cc7-894a-08e90eef734a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After removing stop words: ['Natural', 'language', 'processing', 'fascinating', '.', 'helps', 'computers', 'understand', 'human', 'language', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
        "print(\"After stemming:\", stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEWsCfloenyg",
        "outputId": "f4ccfada-6472-495a-a6e9-256ccb2af616"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After stemming: ['natur', 'languag', 'process', 'fascin', '.', 'help', 'comput', 'understand', 'human', 'languag', '.']\n"
          ]
        }
      ]
    }
  ]
}